{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64b8e13-5926-4a71-945a-6acdbd7fb5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (2.2.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (11.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wordcloud) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (24.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\31326\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e48faa8-dbe3-433a-b146-239e0812ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load original dataset\n",
    "df = pd.read_csv(\"Tweets.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c663aa4-71ff-47d2-909f-f2a54a674c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original column names: Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
      "       'negativereason', 'negativereason_confidence', 'airline',\n",
      "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
      "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
      "       'tweet_location', 'user_timezone'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display column names\n",
    "print(\"Original column names:\", df.columns)\n",
    "\n",
    "# Load English stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7439836a-149e-41c8-aac5-27edc802f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text cleaning function\n",
    "def clean_text(text):\n",
    "    text = str(text)  # Handle NaN\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)       # Remove URLs\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)          # Remove mentions\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)   # Remove punctuation and numbers\n",
    "    text = text.lower()                       # Convert to lowercase\n",
    "    tokens = re.findall(r\"\\b[a-z]+\\b\", text)  # Tokenize with regex\n",
    "    filtered = [w for w in tokens if w not in stop_words]  # Remove stopwords\n",
    "    return \" \".join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "600ce4de-acbf-4b06-b963-628c80486006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "376946d0-d71b-474c-b3b5-29ebc3f6141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  \\\n",
      "6137   @SouthwestAir @Kaneshow @InternJohnRadio @mrer...   \n",
      "1026   @united have been waiting 2 days for my milita...   \n",
      "8414   @JetBlue I would go to Dallas to see my grand ...   \n",
      "11428  @USAirways Have him call me.  I cant wait to s...   \n",
      "6872        @JetBlue That makes two of us! Lol #Blushing   \n",
      "\n",
      "                                              clean_text  \n",
      "6137                      everything return jet go miami  \n",
      "1026   waiting days military bags airport hours away ...  \n",
      "8414   would go dallas see grand baby miss much feel ...  \n",
      "11428  call cant wait see anything happens service re...  \n",
      "6872                           makes two us lol blushing  \n"
     ]
    }
   ],
   "source": [
    "# Show sample cleaned data\n",
    "print(df[[\"text\", \"clean_text\"]].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c36a7ec-655f-450c-ba69-42ebeff0e07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved as 'cleaned_tweets.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save to new CSV\n",
    "df.to_csv(\"cleaned_tweets.csv\", index=False)\n",
    "print(\"Cleaned data saved as 'cleaned_tweets.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
